kable(as.data.frame(prop.table(table(data_clean$default.payment.next.month))),
col.names = c("Vỡ nợ", "Tỷ lệ"), digits = 3)
group_stats <- data_clean %>%
group_by(default.payment.next.month) %>%
summarise(
Mean_LIMIT_BAL = mean(LIMIT_BAL, na.rm = TRUE),
Median_LIMIT_BAL = median(LIMIT_BAL, na.rm = TRUE),
Mean_AGE = mean(AGE, na.rm = TRUE)
)
cat("Thống kê mô tả theo nhóm default:\n")
print(group_stats)
p1_limit_hist <- ggplot(data_clean, aes(x = LIMIT_BAL)) +
geom_histogram(bins = 30, fill = "steelblue", alpha = 0.8, color="white") +
labs(title = "Phân phối Hạn mức tín dụng (LIMIT_BAL)", x = "LIMIT_BAL", y = "Số lượng") +
theme_minimal()
p2_limit_density <- ggplot(data_clean, aes(x = LIMIT_BAL)) +
geom_density(fill = "skyblue", alpha = 0.7) +
labs(title = "Ước lượng mật độ của LIMIT_BAL", x = "LIMIT_BAL", y = "Mật độ") +
theme_minimal()
p3_limit_box <- ggplot(data_clean, aes(y = LIMIT_BAL)) +
geom_boxplot(fill = "lightblue", alpha = 0.8, outlier.colour = "red") +
labs(title = "Boxplot của LIMIT_BAL", y = "LIMIT_BAL") +
theme_minimal() +
coord_flip() # Xoay boxplot cho dễ nhìn hơn khi chỉ có 1
p_age_hist <- ggplot(data_clean, aes(x = AGE)) +
geom_histogram(bins = 30, fill = "seagreen", alpha = 0.8, color="white") +
labs(title = "Phân phối Tuổi (AGE)", x = "AGE", y = "Số lượng") +
theme_minimal()
grid.arrange(p1_limit_hist, p2_limit_density, p3_limit_box, p_age_hist, ncol = 2)
p_sex_bar <- ggplot(data_clean, aes(x = SEX, fill = SEX)) +
geom_bar(alpha = 0.8, show.legend = FALSE) +
scale_fill_manual(values = c("1" = "coral", "2" = "lightgreen")) +
labs(title = "Phân phối Giới tính", x = "SEX (1=Nam, 2=Nữ)", y = "Số lượng") +
theme_minimal()
p_edu_bar <- ggplot(data_clean, aes(x = EDUCATION, fill = EDUCATION)) +
geom_bar(alpha = 0.8, show.legend = FALSE) +
labs(title = "Phân phối Trình độ học vấn",
x = "EDUCATION (1=Sau ĐH, 2=ĐH, 3=THPT, 4=Khác)",
y = "Số lượng") +
theme_minimal()
p_marr_bar <- ggplot(data_clean, aes(x = MARRIAGE, fill = MARRIAGE)) +
geom_bar(alpha = 0.8, show.legend = FALSE) +
labs(title = "Phân phối Tình trạng hôn nhân",
x = "MARRIAGE (1=Kết hôn, 2=Độc thân, 3=Khác)",
y = "Số lượng") +
theme_minimal()
plot_univar_cat <- grid.arrange(p_sex_bar, p_edu_bar, p_marr_bar, ncol = 3)
ggsave(paste0(EDA_PLOTS_DIR, "univariate_categorical.png"), plot = plot_univar_cat, width = 15, height = 5)
p7_limit_default <- ggplot(data_clean, aes(x = default.payment.next.month, y = LIMIT_BAL, fill = default.payment.next.month)) +
geom_violin(alpha = 0.7, trim = FALSE, show.legend = FALSE) +
geom_boxplot(width = 0.1, fill="white", alpha=0.5, show.legend = FALSE) +
labs(title = "LIMIT_BAL theo Tình trạng Vỡ nợ",
x = "Vỡ nợ (0=Không, 1=Có)", y = "LIMIT_BAL") +
theme_minimal()
p8_age_default <- ggplot(data_clean, aes(x = AGE, fill = default.payment.next.month, color = default.payment.next.month)) +
geom_density(alpha = 0.5) +
labs(title = "Phân phối Tuổi (AGE) theo Tình trạng Vỡ nợ",
x = "AGE", y = "Mật độ", fill = "Vỡ nợ", color = "Vỡ nợ") +
theme_minimal()
plot_bivar_num_target <- grid.arrange(p7_limit_default, p8_age_default, ncol = 2)
ggsave(paste0(EDA_PLOTS_DIR, "bivariate_numeric_target.png"), plot = plot_bivar_num_target, width = 12, height = 6)
p9_edu_default <- ggplot(data_clean, aes(x = EDUCATION, fill = default.payment.next.month)) +
geom_bar(position = "fill", alpha = 0.8) +
labs(title = "Tỷ lệ Vỡ nợ theo EDUCATION",
x = "EDUCATION", y = "Tỷ lệ", fill = "Vỡ nợ") +
theme_minimal() +
scale_y_continuous(labels = scales::percent)
p10_marr_default <- ggplot(data_clean, aes(x = MARRIAGE, fill = default.payment.next.month)) +
geom_bar(position = "fill", alpha = 0.8) +
labs(title = "Tỷ lệ Vỡ nợ theo MARRIAGE",
x = "MARRIAGE", y = "Tỷ lệ", fill = "Vỡ nợ") +
theme_minimal() +
scale_y_continuous(labels = scales::percent)
p11_sex_default <- ggplot(data_clean, aes(x = SEX, fill = default.payment.next.month)) +
geom_bar(position = "fill", alpha = 0.8) +
labs(title = "Tỷ lệ Vỡ nợ theo SEX",
x = "SEX", y = "Tỷ lệ", fill = "Vỡ nợ") +
theme_minimal() +
scale_y_continuous(labels = scales::percent)
plot_bivar_cat_target <- grid.arrange(p9_edu_default, p10_marr_default, p11_sex_default, ncol = 3) # Sửa ncol=3
ggsave(paste0(EDA_PLOTS_DIR, "bivariate_categorical_target.png"), plot = plot_bivar_cat_target, width = 15, height = 5)
# AVG_BILL đã được tạo trong chunk setup dữ liệu giả
p13_limit_avgbill <- ggplot(data_clean, aes(x = LIMIT_BAL, y = AVG_BILL, color = default.payment.next.month)) +
geom_point(alpha = 0.4, size=1.5) +
labs(title = "Scatter Plot: LIMIT_BAL vs. AVG_BILL",
x = "LIMIT_BAL", y = "AVG_BILL (Trung bình các BILL_AMT)", color = "Vỡ nợ") +
theme_minimal() +
scale_color_brewer(palette = "Set1")
print(p13_limit_avgbill)
ggsave(paste0(EDA_PLOTS_DIR, "scatter_limit_bal_avg_bill.png"), plot = p13_limit_avgbill, width = 8, height = 6)
corr_matrix <- cor(data_clean[, num_vars], use = "complete.obs") # sử dụng biến num_vars đã có AVG_BILL
# Vẽ và lưu ảnh
png(paste0(EDA_PLOTS_DIR, "correlation_matrix.png"), width = 10, height = 10, units = "in", res = 300)
corrplot(
corr_matrix,
method = "color", # Hoặc "circle", "number"
type = "upper",    # Hiển thị nửa trên ma trận
order = "hclust",  # Sắp xếp theo phân cụm thứ bậc
addCoef.col = "black", # Thêm hệ số tương quan
tl.col = "black",  # Màu chữ của tên biến
tl.srt = 45,       # Xoay tên biến 45 độ
diag = FALSE,      # Không hiển thị đường chéo
number.cex = 0.7,  # Kích thước chữ của hệ số
title = "Ma trận tương quan các biến số",
mar = c(0, 0, 1.5, 0) # Điều chỉnh margin
)
dev.off()
corrplot(corr_matrix, method = "color", type = "upper", order = "hclust",
addCoef.col = "black", tl.col = "black", tl.srt = 45, diag = FALSE, number.cex = 0.7)
t_test_limit_bal <- t.test(LIMIT_BAL ~ default.payment.next.month, data = data_clean)
cat("Kết quả t-test cho LIMIT_BAL theo tình trạng vỡ nợ:\n")
kable(tidy(t_test_limit_bal), caption = "t-test: LIMIT_BAL vs. Default Status", digits = 4)
chi_test_education <- chisq.test(table(data_clean$EDUCATION, data_clean$default.payment.next.month))
cat("Kết quả Chi-squared test cho EDUCATION và tình trạng vỡ nợ:\n")
kable(tidy(chi_test_education), caption = "Chi-squared test: EDUCATION vs. Default Status", digits = 4)
p14_edu_sex_default <- ggplot(data_clean, aes(x = EDUCATION, fill = default.payment.next.month)) +
geom_bar(position = "fill", alpha = 0.8) +
facet_wrap(~SEX, labeller = labeller(SEX = c("1" = "Nam", "2" = "Nữ"))) +
labs(title = "Tỷ lệ Vỡ nợ theo EDUCATION và SEX",
x = "EDUCATION (1=Sau ĐH, 2=ĐH, 3=THPT, 4=Khác)",
y = "Tỷ lệ Vỡ nợ",
fill = "Vỡ nợ") +
theme_minimal() +
scale_y_continuous(labels = scales::percent)
print(p14_edu_sex_default)
ggsave(paste0(EDA_PLOTS_DIR, "default_by_education_sex.png"), plot = p14_edu_sex_default, width = 10, height = 6)
# Tạo một grid tổng hợp mới cho file lưu cuối cùng
final_eda_plot_grid <- grid.arrange(
p1_limit_hist, p_age_hist,
p7_limit_default, p8_age_default,
p9_edu_default, p14_edu_sex_default,
ncol = 2
)
ggsave(paste0(EDA_PLOTS_DIR, "eda_summary_plots.png"),
plot = final_eda_plot_grid,
width = 14, height = 15, dpi=300)
cat("Đã lưu các biểu đồ tóm tắt EDA vào:", paste0(EDA_PLOTS_DIR, "eda_summary_plots.png"), "\n")
source("D:/Documents/Lập Trình R Cho Phân Tích Dữ Liệu/DoAn_CreditCard_Default/1_Scripts/04_preprocessing_for_modeling.R")
source("D:/Documents/Lập Trình R Cho Phân Tích Dữ Liệu/DoAn_CreditCard_Default/1_Scripts/05_model_training.R")
knitr::opts_chunk$set(echo = TRUE)
source("00_setup_environment.R")
library(tidymodels)
library(themis)      # Cho SMOTE
library(randomForest)
library(xgboost)
library(caret)       # Để so sánh với các mô hình trước đó
library(fastDummies) # Cho dummy_cols
library(pROC)        # Cho roc_auc
library(knitr)
# Đọc dữ liệu huấn luyện và kiểm tra
train_data_original <- readRDS(paste0(PROCESSED_DIR, "train_data.rds"))
test_data_original <- readRDS(paste0(PROCESSED_DIR, "test_data.rds"))
# Đảm bảo biến mục tiêu là factor
train_data_original$default.payment.next.month <- as.factor(train_data_original$default.payment.next.month)
if (!is.null(test_data_original$default.payment.next.month)) {
test_data_original$default.payment.next.month <- as.factor(test_data_original$default.payment.next.month)
}
# Kiểm tra cấu trúc dữ liệu
cat("Cấu trúc train_data_original:\n")
str(train_data_original)
cat("Cấu trúc test_data_original:\n")
str(test_data_original)
set.seed(123)
main_recipe <- recipe(default.payment.next.month ~ ., data = train_data_original) %>%
step_rm(any_of(c("ID"))) %>% # Loại bỏ cột ID nếu có
step_novel(all_nominal_predictors(), -all_outcomes()) %>% # Xử lý các level mới trong test
step_dummy(all_nominal_predictors(), -all_outcomes(), one_hot = TRUE) %>% # One-hot encoding
step_zv(all_predictors()) %>% # Loại bỏ các biến có variance bằng 0
step_normalize(all_numeric_predictors()) %>% # Chuẩn hóa các biến số
step_smote(default.payment.next.month, over_ratio = 1) # Cân bằng dữ liệu bằng SMOTE
# Kiểm tra recipe bằng cách prep và bake trên train_data
train_data_balanced_check <- main_recipe %>%
prep() %>%
bake(new_data = NULL)
cat("Tỷ lệ default.payment.next.month sau SMOTE (kiểm tra):\n")
print(table(train_data_balanced_check$default.payment.next.month))
print(prop.table(table(train_data_balanced_check$default.payment.next.month)))
set.seed(123)
cv_folds <- vfold_cv(train_data_original, v = 5, strata = default.payment.next.month)
# Định nghĩa mô hình Random Forest
rf_model_spec <- rand_forest(
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_engine("randomForest") %>%
set_mode("classification")
# Tạo lưới tham số
num_features <- length(all_numeric_predictors() %>%
select(train_data_original, .) %>%
names()) +
length(all_nominal_predictors() %>%
select(train_data_original, .) %>%
names()) * 2 # Giả sử mỗi biến phân loại tạo 2 dummy variables
mtry_low <- max(1, floor(sqrt(num_features)))
mtry_high <- min(num_features, floor(sqrt(num_features) * 1.5))
rf_grid <- grid_regular(
mtry(range = c(mtry_low, mtry_high)),
trees(range = c(500L, 1000L)),
min_n(range = c(5L, 15L)),
levels = c(mtry = 2, trees = 2, min_n = 2)
)
# Workflow cho Random Forest
rf_workflow <- workflow() %>%
add_model(rf_model_spec) %>%
add_recipe(main_recipe)
# Tinh chỉnh với Grid Search
set.seed(123)
rf_tune_results <- tune_grid(
rf_workflow,
resamples = cv_folds,
grid = rf_grid,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE, verbose = TRUE)
)
cat("\nKết quả tinh chỉnh Random Forest (5 kết quả tốt nhất theo ROC-AUC):\n")
show_best(rf_tune_results, metric = "roc_auc", n = 5) %>% kable(caption = "Top 5 siêu tham số Random Forest")
# Chọn mô hình tốt nhất
best_rf_params <- select_best(rf_tune_results, metric = "roc_auc")
cat("\nSiêu tham số tốt nhất cho Random Forest:\n")
print(best_rf_params)
# Finalize workflow với siêu tham số tốt nhất
final_rf_workflow <- finalize_workflow(rf_workflow, best_rf_params)
# Fit mô hình trên toàn bộ tập huấn luyện
set.seed(123)
final_rf_model <- fit(final_rf_workflow, data = train_data_original)
# Lưu mô hình
saveRDS(final_rf_model, paste0(MODELS_DIR, "random_forest_tuned_final.rds"))
cat("Đã lưu mô hình Random Forest tinh chỉnh vào:", paste0(MODELS_DIR, "random_forest_tuned_final.rds"), "\n")
# Định nghĩa mô hình XGBoost
xgb_model_spec <- boost_tree(
mtry = tune(),
trees = tune(),
min_n = tune(),
learn_rate = tune(),
tree_depth = tune(),
sample_size = tune()
) %>%
set_engine("xgboost") %>%
set_mode("classification")
# Tạo lưới ngẫu nhiên
set.seed(456)
xgb_grid <- grid_random(
mtry(range = c(max(1L, floor(0.7 * num_features)), num_features)),
trees(range = c(100L, 500L)),
min_n(range = c(1L, 5L)),
learn_rate(range = c(0.01, 0.3)),
tree_depth(range = c(3L, 6L)),
sample_prop(range = c(0.7, 1.0)),
size = 10
)
# Workflow cho XGBoost
xgb_workflow <- workflow() %>%
add_model(xgb_model_spec) %>%
add_recipe(main_recipe)
# Tinh chỉnh với Random Search
set.seed(123)
xgb_tune_results <- tune_grid(
xgb_workflow,
resamples = cv_folds,
grid = xgb_grid,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE, verbose = TRUE)
)
cat("\nKết quả tinh chỉnh XGBoost (5 kết quả tốt nhất theo ROC-AUC):\n")
show_best(xgb_tune_results, metric = "roc_auc", n = 5) %>% kable(caption = "Top 5 siêu tham số XGBoost")
# Chọn mô hình tốt nhất
best_xgb_params <- select_best(xgb_tune_results, metric = "roc_auc")
cat("\nSiêu tham số tốt nhất cho XGBoost:\n")
print(best_xgb_params)
# Finalize workflow với siêu tham số tốt nhất
final_xgb_workflow <- finalize_workflow(xgb_workflow, best_xgb_params)
# Fit mô hình trên toàn bộ tập huấn luyện
set.seed(123)
final_xgb_model <- fit(final_xgb_workflow, data = train_data_original)
# Lưu mô hình
saveRDS(final_xgb_model, paste0(MODELS_DIR, "xgboost_tuned_final.rds"))
cat("Đã lưu mô hình XGBoost tinh chỉnh vào:", paste0(MODELS_DIR, "xgboost_tuned_final.rds"), "\n")
# Tạo và lưu mô hình Logistic Regression
lr_recipe <- recipe(default.payment.next.month ~ ., data = train_data_original) %>%
step_rm(any_of(c("ID"))) %>%
step_novel(all_nominal_predictors(), -all_outcomes()) %>%
step_dummy(all_nominal_predictors(), -all_outcomes(), one_hot = TRUE) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric_predictors()) %>%
step_smote(default.payment.next.month, over_ratio = 1)
lr_spec <- logistic_reg() %>% set_engine("glm")
lr_workflow <- workflow() %>% add_recipe(lr_recipe) %>% add_model(lr_spec)
model_lr_fitted <- fit(lr_workflow, data = train_data_original)
saveRDS(model_lr_fitted, paste0(MODELS_DIR, "logistic_regression_final.rds"))
# Dự đoán trên tập kiểm tra
rf_pred_prob <- predict(final_rf_model, test_data_original, type = "prob")$.pred_1
rf_pred_class <- predict(final_rf_model, test_data_original)$.pred_class
rf_roc <- roc(response = test_data_original$default.payment.next.month,
predictor = rf_pred_prob,
levels = levels(test_data_original$default.payment.next.month))
rf_conf_matrix <- confusionMatrix(rf_pred_class, test_data_original$default.payment.next.month, positive = "1")
xgb_pred_prob <- predict(final_xgb_model, test_data_original, type = "prob")$.pred_1
xgb_pred_class <- predict(final_xgb_model, test_data_original)$.pred_class
xgb_roc <- roc(response = test_data_original$default.payment.next.month,
predictor = xgb_pred_prob,
levels = levels(test_data_original$default.payment.next.month))
xgb_conf_matrix <- confusionMatrix(xgb_pred_class, test_data_original$default.payment.next.month, positive = "1")
lr_pred_prob <- predict(model_lr_fitted, test_data_original, type = "prob")$.pred_1
lr_pred_class <- predict(model_lr_fitted, test_data_original)$.pred_class
lr_roc <- roc(response = test_data_original$default.payment.next.month,
predictor = lr_pred_prob,
levels = levels(test_data_original$default.payment.next.month))
lr_conf_matrix <- confusionMatrix(lr_pred_class, test_data_original$default.payment.next.month, positive = "1")
# Tạo bảng tổng hợp hiệu suất
performance_summary_tuned <- data.frame(
Model = c("Logistic Regression", "Random Forest (Tuned)", "XGBoost (Tuned)"),
Accuracy = c(lr_conf_matrix$overall["Accuracy"], rf_conf_matrix$overall["Accuracy"], xgb_conf_matrix$overall["Accuracy"]),
Precision = c(lr_conf_matrix$byClass["Precision"], rf_conf_matrix$byClass["Precision"], xgb_conf_matrix$byClass["Precision"]),
Recall = c(lr_conf_matrix$byClass["Recall"], rf_conf_matrix$byClass["Recall"], xgb_conf_matrix$byClass["Recall"]),
F1 = c(lr_conf_matrix$byClass["F1"], rf_conf_matrix$byClass["F1"], xgb_conf_matrix$byClass["F1"]),
AUC = c(as.numeric(auc(lr_roc)), as.numeric(auc(rf_roc)), as.numeric(auc(xgb_roc)))
)
cat("\nTổng hợp hiệu suất các mô hình trên tập kiểm tra:\n")
kable(performance_summary_tuned, caption = "Tổng hợp hiệu suất các mô hình (đã tinh chỉnh)", digits = 4)
write.csv(performance_summary_tuned,
paste0(RESULTS_DIR, "model_performance/performance_metrics_tuned_summary.csv"),
row.names = FALSE)
cat("\nĐã lưu bảng tổng hợp hiệu suất vào:",
paste0(RESULTS_DIR, "model_performance/performance_metrics_tuned_summary.csv"), "\n")
# Sử dụng ggplot2 để vẽ đẹp hơn nếu muốn, ở đây dùng plot cơ bản
png(paste0(RESULTS_DIR, "model_performance/roc_curves_tuned_comparison.png"), width = 800, height = 600)
plot(lr_roc, col = "blue", main = "So sánh ROC Curves (Mô hình đã Tinh chỉnh)", legacy.axes = TRUE)
plot(rf_roc, col = "green", add = TRUE)
plot(xgb_roc, col = "red", add = TRUE)
legend("bottomright",
legend = c(paste0("Logistic Regression (AUC: ", sprintf("%.3f", auc(lr_roc)), ")"),
paste0("Random Forest Tuned (AUC: ", sprintf("%.3f", auc(rf_roc)), ")"),
paste0("XGBoost Tuned (AUC: ", sprintf("%.3f", auc(xgb_roc)), ")")
),
col = c("blue", "green", "red"),
lty = 1, lwd = 2, cex = 0.9)
dev.off()
cat("Đã lưu biểu đồ ROC vào:",
paste0(RESULTS_DIR, "model_performance/roc_curves_tuned_comparison.png"), "\n")
# Hiển thị lại trong RMarkdown output (nếu chạy interactive)
# Hoặc dùng lại code plot không qua png() để hiển thị trực tiếp
plot(lr_roc, col = "blue", main = "So sánh ROC Curves (Mô hình đã Tinh chỉnh)", legacy.axes = TRUE)
plot(rf_roc, col = "green", add = TRUE)
plot(xgb_roc, col = "red", add = TRUE)
legend("bottomright",
legend = c(paste0("Logistic Regression (AUC: ", sprintf("%.3f", auc(lr_roc)), ")"),
paste0("Random Forest Tuned (AUC: ", sprintf("%.3f", auc(rf_roc)), ")"),
paste0("XGBoost Tuned (AUC: ", sprintf("%.3f", auc(xgb_roc)), ")")
),
col = c("blue", "green", "red"),
lty = 1, lwd = 2, cex = 0.9)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.align = 'center')
source("00_setup_environment.R")
library(tidymodels)
library(pROC)
library(caret)
library(vip)
library(ggplot2)
library(patchwork)
library(dplyr)
library(kableExtra)
# Load test data
test_data_path <- paste0(PROCESSED_DIR, "test_data.rds")
if (file.exists(test_data_path)) {
test_data <- readRDS(test_data_path)
cat("Đã tải test_data.rds thành công.\n")
} else {
stop("Không tìm thấy file test_data.rds. Hãy chắc chắn script 04 đã chạy.")
}
# Đảm bảo biến mục tiêu là factor và có levels đúng
# (Giả sử levels là "0" và "1", với "1" là positive class - vỡ nợ)
test_data$default.payment.next.month <- factor(test_data$default.payment.next.month, levels = c("0", "1"))
cat("Levels của biến mục tiêu trong test_data:\n")
print(levels(test_data$default.payment.next.month))
# Load models
# Models này được lưu từ script 06_hyperparameter_tuning.Rmd và là các workflow objects của tidymodels
model_lr_path <- paste0(MODELS_DIR, "logistic_regression_final.rds")
model_rf_tuned_path <- paste0(MODELS_DIR, "random_forest_tuned_final.rds")
model_xgb_tuned_path <- paste0(MODELS_DIR, "xgboost_tuned_final.rds")
if (file.exists(model_lr_path) && file.exists(model_rf_tuned_path) && file.exists(model_xgb_tuned_path)) {
model_lr <- readRDS(model_lr_path)
model_rf_tuned <- readRDS(model_rf_tuned_path)
model_xgb_tuned <- readRDS(model_xgb_tuned_path)
cat("Đã tải các mô hình thành công.\n")
} else {
stop("Không tìm thấy một hoặc nhiều file mô hình. Hãy chắc chắn script 06 đã chạy và lưu các mô hình.")
}
# Kiểm tra nhanh cấu trúc một mô hình (ví dụ RF)
# print(model_rf_tuned)
# Logistic Regression
pred_prob_lr <- predict(model_lr, new_data = test_data, type = "prob")$.pred_1
pred_class_lr <- predict(model_lr, new_data = test_data, type = "class")$.pred_class
# Random Forest (Tuned)
pred_prob_rf <- predict(model_rf_tuned, new_data = test_data, type = "prob")$.pred_1
pred_class_rf <- predict(model_rf_tuned, new_data = test_data, type = "class")$.pred_class
# XGBoost (Tuned)
pred_prob_xgb <- predict(model_xgb_tuned, new_data = test_data, type = "prob")$.pred_1
pred_class_xgb <- predict(model_xgb_tuned, new_data = test_data, type = "class")$.pred_class
# Tạo dataframe chứa kết quả thực tế và dự đoán (để dùng với yardstick)
results_df <- tibble(
truth = test_data$default.payment.next.month,
prob_lr = pred_prob_lr,
class_lr = pred_class_lr,
prob_rf = pred_prob_rf,
class_class_rf = pred_class_rf,
prob_xgb = pred_prob_xgb,
class_xgb = pred_class_xgb
)
# Hàm trợ giúp để hiển thị ma trận nhầm lẫn đẹp hơn
print_cm <- function(cm_object, model_name) {
cat("\nMa trận nhầm lẫn cho:", model_name, "\n")
# print(cm_object) # In bản đầy đủ
# Trích xuất bảng ma trận
cm_table <- cm_object$table
# Trích xuất các số liệu thống kê tổng thể và theo lớp
overall_stats <- cm_object$overall
byclass_stats <- cm_object$byClass
# In tóm tắt
cat(" Accuracy:", round(overall_stats["Accuracy"], 4), "\n")
cat(" Kappa:", round(overall_stats["Kappa"], 4), "\n")
cat(" Sensitivity (Recall for class 1):", round(byclass_stats["Sensitivity"], 4), "\n")
cat(" Specificity (Recall for class 0):", round(byclass_stats["Specificity"], 4), "\n")
cat(" Precision (for class 1):", round(byclass_stats["Precision"], 4), "\n")
cat(" F1-Score (for class 1):", round(byclass_stats["F1"], 4), "\n")
cat(" Balanced Accuracy:", round(byclass_stats["Balanced Accuracy"], 4), "\n")
# Sử dụng kable để hiển thị ma trận đẹp hơn
cm_df <- as.data.frame(cm_table)
cm_pivot <- tidyr::pivot_wider(cm_df, names_from = Prediction, values_from = Freq)
kable(cm_pivot, caption = paste("Confusion Matrix:", model_name)) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F) %>%
add_header_above(c(" " = 1, "Predicted" = ncol(cm_pivot)-1)) %>%
column_spec(1, bold = T) %>%
footnote(general = "Rows: Actual, Columns: Predicted") %>% print()
}
# Sử dụng caret::confusionMatrix (vì nó cung cấp nhiều số liệu)
# Lưu ý: 'positive' class là "1" (vỡ nợ)
cm_lr <- confusionMatrix(data = pred_class_lr, reference = test_data$default.payment.next.month, positive = "1")
cm_rf <- confusionMatrix(data = pred_class_rf, reference = test_data$default.payment.next.month, positive = "1")
cm_xgb <- confusionMatrix(data = pred_class_xgb, reference = test_data$default.payment.next.month, positive = "1")
print_cm(cm_lr, "Logistic Regression")
print_cm(cm_rf, "Random Forest (Tuned)")
print_cm(cm_xgb, "XGBoost (Tuned)")
# Tính toán ROC objects từ pROC
roc_lr <- roc(response = test_data$default.payment.next.month, predictor = pred_prob_lr, levels = c("0", "1"))
roc_rf <- roc(response = test_data$default.payment.next.month, predictor = pred_prob_rf, levels = c("0", "1"))
roc_xgb <- roc(response = test_data$default.payment.next.month, predictor = pred_prob_xgb, levels = c("0", "1"))
# Lấy giá trị AUC
auc_lr_val <- auc(roc_lr)
auc_rf_val <- auc(roc_rf)
auc_xgb_val <- auc(roc_xgb)
# Vẽ đường cong ROC
ggroc_obj <- ggroc(list(LR = roc_lr, RF_Tuned = roc_rf, XGB_Tuned = roc_xgb), legacy.axes = TRUE) +
geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1), color="grey", linetype="dashed") +
labs(title = "So sánh Đường cong ROC",
x = "1 - Specificity (False Positive Rate)",
y = "Sensitivity (True Positive Rate)",
color = "Mô hình") +
annotate("text", x = 0.75, y = 0.25, label = paste("LR AUC:", sprintf("%.3f", auc_lr_val))) +
annotate("text", x = 0.75, y = 0.18, label = paste("RF AUC:", sprintf("%.3f", auc_rf_val))) +
annotate("text", x = 0.75, y = 0.11, label = paste("XGB AUC:", sprintf("%.3f", auc_xgb_val))) +
theme_minimal()
print(ggroc_obj)
# Lưu biểu đồ
ggsave(paste0(RESULTS_DIR, "model_performance/roc_curves_comparison_final.png"), plot = ggroc_obj, width = 8, height = 6)
cat("Đã lưu biểu đồ ROC vào thư mục results/model_performance.\n")
# Sử dụng yardstick để tính PR curves
pr_lr_data <- results_df %>% pr_curve(truth, prob_lr)
pr_rf_data <- results_df %>% pr_curve(truth, prob_rf)
pr_xgb_data <- results_df %>% pr_curve(truth, prob_xgb)
# Tính AUC-PR
auc_pr_lr_val <- pr_auc(results_df, truth, prob_lr)$.estimate
auc_pr_rf_val <- pr_auc(results_df, truth, prob_rf)$.estimate
auc_pr_xgb_val <- pr_auc(results_df, truth, prob_xgb)$.estimate
# Vẽ PR curves
pr_plot <- ggplot() +
geom_path(data = pr_lr_data, aes(x = recall, y = precision, color = "Logistic Regression"), linewidth = 1) +
geom_path(data = pr_rf_data, aes(x = recall, y = precision, color = "Random Forest (Tuned)"), linewidth = 1) +
geom_path(data = pr_xgb_data, aes(x = recall, y = precision, color = "XGBoost (Tuned)"), linewidth = 1) +
labs(title = "So sánh Đường cong Precision-Recall",
x = "Recall",
y = "Precision",
color = "Mô hình") +
annotate("text", x = 0.75, y = 0.85, label = paste("LR AUC-PR:", sprintf("%.3f", auc_pr_lr_val))) +
annotate("text", x = 0.75, y = 0.78, label = paste("RF AUC-PR:", sprintf("%.3f", auc_pr_rf_val))) +
annotate("text", x = 0.75, y = 0.71, label = paste("XGB AUC-PR:", sprintf("%.3f", auc_pr_xgb_val))) +
theme_minimal() +
scale_color_brewer(palette = "Set1")
print(pr_plot)
# Lưu biểu đồ
ggsave(paste0(RESULTS_DIR, "model_performance/pr_curves_comparison_final.png"), plot = pr_plot, width = 8, height = 6)
cat("Đã lưu biểu đồ PR vào thư mục results/model_performance.\n")
metrics_summary <- data.frame(
Model = c("Logistic Regression", "Random Forest (Tuned)", "XGBoost (Tuned)"),
Accuracy = c(cm_lr$overall["Accuracy"], cm_rf$overall["Accuracy"], cm_xgb$overall["Accuracy"]),
Precision_Class1 = c(cm_lr$byClass["Precision"], cm_rf$byClass["Precision"], cm_xgb$byClass["Precision"]),
Recall_Class1 = c(cm_lr$byClass["Sensitivity"], cm_rf$byClass["Sensitivity"], cm_xgb$byClass["Sensitivity"]),
F1_Score_Class1 = c(cm_lr$byClass["F1"], cm_rf$byClass["F1"], cm_xgb$byClass["F1"]),
Specificity_Class0 = c(cm_lr$byClass["Specificity"], cm_rf$byClass["Specificity"], cm_xgb$byClass["Specificity"]),
Balanced_Accuracy = c(cm_lr$byClass["Balanced Accuracy"], cm_rf$byClass["Balanced Accuracy"], cm_xgb$byClass["Balanced Accuracy"]),
AUC_ROC = c(auc_lr_val, auc_rf_val, auc_xgb_val),
AUC_PR = c(auc_pr_lr_val, auc_pr_rf_val, auc_pr_xgb_val)
)
# Làm tròn số liệu
metrics_summary <- metrics_summary %>%
mutate(across(where(is.numeric), ~round(., 4)))
kable(metrics_summary, caption = "Bảng Tổng hợp Hiệu suất Các Mô hình trên Tập Kiểm tra") %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F) %>%
column_spec(1, bold = T)
# Lưu bảng
write.csv(metrics_summary, paste0(RESULTS_DIR, "model_performance/performance_metrics_summary_final.csv"), row.names = FALSE)
cat("Đã lưu bảng tổng hợp hiệu suất vào thư mục results/model_performance.\n")
