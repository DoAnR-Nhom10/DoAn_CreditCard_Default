---
title: "Đánh giá và So sánh Mô hình Dự đoán Vỡ Nợ Thẻ Tín Dụng"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.align = 'center')
source("00_setup_environment.R")
library(tidymodels)
library(pROC)
library(caret)
library(vip)
library(ggplot2)
library(patchwork)
library(dplyr)
library(kableExtra)
```

## 1. Giới thiệu

Mục tiêu của script này là đánh giá chi tiết và so sánh hiệu năng của các mô hình đã được huấn luyện và tinh chỉnh:
1.  Logistic Regression (LR)
2.  Random Forest (RF - đã tinh chỉnh)
3.  XGBoost (XGB - đã tinh chỉnh)

Chúng ta sẽ sử dụng tập dữ liệu kiểm tra (`test_data`) để đánh giá. Các độ đo chính bao gồm Accuracy, Precision, Recall, F1-Score, AUC-ROC, và AUC-PR. Ngoài ra, chúng ta sẽ phân tích độ quan trọng của các biến.

## 2. Tải Dữ liệu và Mô hình

```{r load-data-models}
# Load test data
test_data_path <- paste0(PROCESSED_DIR, "test_data.rds")
if (file.exists(test_data_path)) {
  test_data <- readRDS(test_data_path)
  cat("Đã tải test_data.rds thành công.\n")
} else {
  stop("Không tìm thấy file test_data.rds. Hãy chắc chắn script 04 đã chạy.")
}

# Đảm bảo biến mục tiêu là factor và có levels đúng
# (Giả sử levels là "0" và "1", với "1" là positive class - vỡ nợ)
test_data$default.payment.next.month <- factor(test_data$default.payment.next.month, levels = c("0", "1"))
cat("Levels của biến mục tiêu trong test_data:\n")
print(levels(test_data$default.payment.next.month))


# Load models
# Models này được lưu từ script 06_hyperparameter_tuning.Rmd và là các workflow objects của tidymodels
model_lr_path <- paste0(MODELS_DIR, "logistic_regression_final.rds")
model_rf_tuned_path <- paste0(MODELS_DIR, "random_forest_tuned_final.rds")
model_xgb_tuned_path <- paste0(MODELS_DIR, "xgboost_tuned_final.rds")

if (file.exists(model_lr_path) && file.exists(model_rf_tuned_path) && file.exists(model_xgb_tuned_path)) {
  model_lr <- readRDS(model_lr_path)
  model_rf_tuned <- readRDS(model_rf_tuned_path)
  model_xgb_tuned <- readRDS(model_xgb_tuned_path)
  cat("Đã tải các mô hình thành công.\n")
} else {
  stop("Không tìm thấy một hoặc nhiều file mô hình. Hãy chắc chắn script 06 đã chạy và lưu các mô hình.")
}

# Kiểm tra nhanh cấu trúc một mô hình (ví dụ RF)
# print(model_rf_tuned)
```

## 3. Dự đoán trên Tập Kiểm tra

Chúng ta sẽ thực hiện dự đoán xác suất và lớp cho từng mô hình trên tập `test_data`.

```{r predictions}
# Logistic Regression
pred_prob_lr <- predict(model_lr, new_data = test_data, type = "prob")$.pred_1
pred_class_lr <- predict(model_lr, new_data = test_data, type = "class")$.pred_class

# Random Forest (Tuned)
pred_prob_rf <- predict(model_rf_tuned, new_data = test_data, type = "prob")$.pred_1
pred_class_rf <- predict(model_rf_tuned, new_data = test_data, type = "class")$.pred_class

# XGBoost (Tuned)
pred_prob_xgb <- predict(model_xgb_tuned, new_data = test_data, type = "prob")$.pred_1
pred_class_xgb <- predict(model_xgb_tuned, new_data = test_data, type = "class")$.pred_class

# Tạo dataframe chứa kết quả thực tế và dự đoán (để dùng với yardstick)
results_df <- tibble(
  truth = test_data$default.payment.next.month,
  prob_lr = pred_prob_lr,
  class_lr = pred_class_lr,
  prob_rf = pred_prob_rf,
  class_class_rf = pred_class_rf,
  prob_xgb = pred_prob_xgb,
  class_xgb = pred_class_xgb
)
```

## 4. Đánh giá Hiệu năng Mô hình

### 4.1. Ma trận Nhầm lẫn (Confusion Matrix)

```{r confusion-matrices}
# Hàm trợ giúp để hiển thị ma trận nhầm lẫn đẹp hơn
print_cm <- function(cm_object, model_name) {
  cat("\nMa trận nhầm lẫn cho:", model_name, "\n")
  # print(cm_object) # In bản đầy đủ
  
  # Trích xuất bảng ma trận
  cm_table <- cm_object$table
  
  # Trích xuất các số liệu thống kê tổng thể và theo lớp
  overall_stats <- cm_object$overall
  byclass_stats <- cm_object$byClass
  
  # In tóm tắt
  cat(" Accuracy:", round(overall_stats["Accuracy"], 4), "\n")
  cat(" Kappa:", round(overall_stats["Kappa"], 4), "\n")
  cat(" Sensitivity (Recall for class 1):", round(byclass_stats["Sensitivity"], 4), "\n")
  cat(" Specificity (Recall for class 0):", round(byclass_stats["Specificity"], 4), "\n")
  cat(" Precision (for class 1):", round(byclass_stats["Precision"], 4), "\n")
  cat(" F1-Score (for class 1):", round(byclass_stats["F1"], 4), "\n")
  cat(" Balanced Accuracy:", round(byclass_stats["Balanced Accuracy"], 4), "\n")
  
  # Sử dụng kable để hiển thị ma trận đẹp hơn
  cm_df <- as.data.frame(cm_table)
  cm_pivot <- tidyr::pivot_wider(cm_df, names_from = Prediction, values_from = Freq)
  
  kable(cm_pivot, caption = paste("Confusion Matrix:", model_name)) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F) %>%
    add_header_above(c(" " = 1, "Predicted" = ncol(cm_pivot)-1)) %>%
    column_spec(1, bold = T) %>%
    footnote(general = "Rows: Actual, Columns: Predicted") %>% print()
}

# Sử dụng caret::confusionMatrix (vì nó cung cấp nhiều số liệu)
# Lưu ý: 'positive' class là "1" (vỡ nợ)
cm_lr <- confusionMatrix(data = pred_class_lr, reference = test_data$default.payment.next.month, positive = "1")
cm_rf <- confusionMatrix(data = pred_class_rf, reference = test_data$default.payment.next.month, positive = "1")
cm_xgb <- confusionMatrix(data = pred_class_xgb, reference = test_data$default.payment.next.month, positive = "1")

print_cm(cm_lr, "Logistic Regression")
print_cm(cm_rf, "Random Forest (Tuned)")
print_cm(cm_xgb, "XGBoost (Tuned)")
```

### 4.2. Đường cong ROC và AUC-ROC

Đường cong ROC (Receiver Operating Characteristic) thể hiện khả năng phân biệt của mô hình ở các ngưỡng khác nhau. AUC (Area Under the Curve) là diện tích dưới đường cong ROC.

```{r roc-curves, fig.width=8, fig.height=6}
# Tính toán ROC objects từ pROC
roc_lr <- roc(response = test_data$default.payment.next.month, predictor = pred_prob_lr, levels = c("0", "1"))
roc_rf <- roc(response = test_data$default.payment.next.month, predictor = pred_prob_rf, levels = c("0", "1"))
roc_xgb <- roc(response = test_data$default.payment.next.month, predictor = pred_prob_xgb, levels = c("0", "1"))

# Lấy giá trị AUC
auc_lr_val <- auc(roc_lr)
auc_rf_val <- auc(roc_rf)
auc_xgb_val <- auc(roc_xgb)

# Vẽ đường cong ROC
ggroc_obj <- ggroc(list(LR = roc_lr, RF_Tuned = roc_rf, XGB_Tuned = roc_xgb), legacy.axes = TRUE) +
  geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1), color="grey", linetype="dashed") +
  labs(title = "So sánh Đường cong ROC",
       x = "1 - Specificity (False Positive Rate)",
       y = "Sensitivity (True Positive Rate)",
       color = "Mô hình") +
  annotate("text", x = 0.75, y = 0.25, label = paste("LR AUC:", sprintf("%.3f", auc_lr_val))) +
  annotate("text", x = 0.75, y = 0.18, label = paste("RF AUC:", sprintf("%.3f", auc_rf_val))) +
  annotate("text", x = 0.75, y = 0.11, label = paste("XGB AUC:", sprintf("%.3f", auc_xgb_val))) +
  theme_minimal()

print(ggroc_obj)

# Lưu biểu đồ
ggsave(paste0(RESULTS_DIR, "model_performance/roc_curves_comparison_final.png"), plot = ggroc_obj, width = 8, height = 6)
cat("Đã lưu biểu đồ ROC vào thư mục results/model_performance.\n")
```

### 4.3. Đường cong Precision-Recall và AUC-PR

Đường cong Precision-Recall (PR) đặc biệt hữu ích cho các tập dữ liệu mất cân bằng, vì nó tập trung vào hiệu suất của lớp thiểu số.

```{r pr-curves, fig.width=8, fig.height=6}
# Sử dụng yardstick để tính PR curves
pr_lr_data <- results_df %>% pr_curve(truth, prob_lr)
pr_rf_data <- results_df %>% pr_curve(truth, prob_rf)
pr_xgb_data <- results_df %>% pr_curve(truth, prob_xgb)

# Tính AUC-PR
auc_pr_lr_val <- pr_auc(results_df, truth, prob_lr)$.estimate
auc_pr_rf_val <- pr_auc(results_df, truth, prob_rf)$.estimate
auc_pr_xgb_val <- pr_auc(results_df, truth, prob_xgb)$.estimate

# Vẽ PR curves
pr_plot <- ggplot() +
  geom_path(data = pr_lr_data, aes(x = recall, y = precision, color = "Logistic Regression"), linewidth = 1) +
  geom_path(data = pr_rf_data, aes(x = recall, y = precision, color = "Random Forest (Tuned)"), linewidth = 1) +
  geom_path(data = pr_xgb_data, aes(x = recall, y = precision, color = "XGBoost (Tuned)"), linewidth = 1) +
  labs(title = "So sánh Đường cong Precision-Recall",
       x = "Recall",
       y = "Precision",
       color = "Mô hình") +
  annotate("text", x = 0.75, y = 0.85, label = paste("LR AUC-PR:", sprintf("%.3f", auc_pr_lr_val))) +
  annotate("text", x = 0.75, y = 0.78, label = paste("RF AUC-PR:", sprintf("%.3f", auc_pr_rf_val))) +
  annotate("text", x = 0.75, y = 0.71, label = paste("XGB AUC-PR:", sprintf("%.3f", auc_pr_xgb_val))) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1")

print(pr_plot)

# Lưu biểu đồ
ggsave(paste0(RESULTS_DIR, "model_performance/pr_curves_comparison_final.png"), plot = pr_plot, width = 8, height = 6)
cat("Đã lưu biểu đồ PR vào thư mục results/model_performance.\n")
```

### 4.4. Bảng tổng hợp các Độ đo

```{r metrics-summary-table}
metrics_summary <- data.frame(
  Model = c("Logistic Regression", "Random Forest (Tuned)", "XGBoost (Tuned)"),
  Accuracy = c(cm_lr$overall["Accuracy"], cm_rf$overall["Accuracy"], cm_xgb$overall["Accuracy"]),
  Precision_Class1 = c(cm_lr$byClass["Precision"], cm_rf$byClass["Precision"], cm_xgb$byClass["Precision"]),
  Recall_Class1 = c(cm_lr$byClass["Sensitivity"], cm_rf$byClass["Sensitivity"], cm_xgb$byClass["Sensitivity"]),
  F1_Score_Class1 = c(cm_lr$byClass["F1"], cm_rf$byClass["F1"], cm_xgb$byClass["F1"]),
  Specificity_Class0 = c(cm_lr$byClass["Specificity"], cm_rf$byClass["Specificity"], cm_xgb$byClass["Specificity"]),
  Balanced_Accuracy = c(cm_lr$byClass["Balanced Accuracy"], cm_rf$byClass["Balanced Accuracy"], cm_xgb$byClass["Balanced Accuracy"]),
  AUC_ROC = c(auc_lr_val, auc_rf_val, auc_xgb_val),
  AUC_PR = c(auc_pr_lr_val, auc_pr_rf_val, auc_pr_xgb_val)
)

# Làm tròn số liệu
metrics_summary <- metrics_summary %>%
  mutate(across(where(is.numeric), ~round(., 4)))

kable(metrics_summary, caption = "Bảng Tổng hợp Hiệu suất Các Mô hình trên Tập Kiểm tra") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F) %>%
  column_spec(1, bold = T)

# Lưu bảng
write.csv(metrics_summary, paste0(RESULTS_DIR, "model_performance/performance_metrics_summary_final.csv"), row.names = FALSE)
cat("Đã lưu bảng tổng hợp hiệu suất vào thư mục results/model_performance.\n")
```

## 5. Phân tích Độ quan trọng của Biến (Feature Importance)

Chúng ta sẽ xem xét các biến quan trọng nhất đối với mô hình Random Forest và XGBoost.

### 5.1. Random Forest (Tuned)

```{r rf-feature-importance, fig.width=10, fig.height=8}
# RF model (workflow) từ script 06 sử dụng engine "randomForest"
# Chúng ta cần trích xuất mô hình gốc để sử dụng varImpPlot hoặc importance()
# Hoặc sử dụng vip::vip() trực tiếp trên workflow object nếu hỗ trợ

# Cách 1: Dùng vip (khuyến nghị cho tidymodels)
# vip_rf <- vip(model_rf_tuned, num_features = 20, geom = "col", aesthetics = list(fill = "steelblue")) +
#   labs(title = "Độ quan trọng của Biến - Random Forest (Tuned)",
#        subtitle = "Dựa trên Mean Decrease Gini (mặc định cho RF)") +
#   theme_minimal()
# print(vip_rf)

# Cách 2: Trích xuất mô hình randomForest gốc (nếu cần độ linh hoạt của randomForest::importance)
# Kiểm tra xem model_rf_tuned$fit$fit$fit là đối tượng randomForest
if (inherits(model_rf_tuned$fit$fit$fit, "randomForest")) {
    rf_engine_model <- model_rf_tuned$fit$fit$fit
    
    # Lấy tầm quan trọng
    rf_importance_df <- as.data.frame(importance(rf_engine_model))
    rf_importance_df$Variable <- rownames(rf_importance_df)
    rownames(rf_importance_df) <- NULL
    
    # Sắp xếp theo MeanDecreaseGini và lấy top 20
    rf_importance_top20 <- rf_importance_df %>%
      arrange(desc(MeanDecreaseGini)) %>%
      head(20)

    vip_rf_plot <- ggplot(rf_importance_top20, aes(x = reorder(Variable, MeanDecreaseGini), y = MeanDecreaseGini)) +
      geom_col(fill = "skyblue") +
      coord_flip() +
      labs(title = "Top 20 Biến Quan trọng - Random Forest (Tuned)",
           subtitle = "Dựa trên Mean Decrease Gini",
           x = "Biến", y = "Mean Decrease Gini") +
      theme_minimal()
    print(vip_rf_plot)
    
    ggsave(paste0(RESULTS_DIR, "feature_importance/rf_feature_importance_final.png"), plot = vip_rf_plot, width = 10, height = 8)
    cat("Đã lưu biểu đồ độ quan trọng RF vào thư mục results/feature_importance.\n")
} else {
    cat("Không thể trích xuất mô hình randomForest gốc từ workflow. Sử dụng vip() nếu có thể.\n")
    # Thử lại với vip() như một phương án dự phòng
    tryCatch({
        vip_rf_plot <- vip(model_rf_tuned, num_features = 20, geom = "col", aesthetics = list(fill = "steelblue")) +
          labs(title = "Độ quan trọng của Biến - Random Forest (Tuned)",
               subtitle = "Mặc định từ vip()") +
          theme_minimal()
        print(vip_rf_plot)
        ggsave(paste0(RESULTS_DIR, "feature_importance/rf_feature_importance_final.png"), plot = vip_rf_plot, width = 10, height = 8)
        cat("Đã lưu biểu đồ độ quan trọng RF (từ vip) vào thư mục results/feature_importance.\n")
    }, error = function(e) {
        cat("Lỗi khi tạo biểu đồ vip cho RF:", conditionMessage(e), "\n")
    })
}
```

### 5.2. XGBoost (Tuned)

```{r xgb-feature-importance, fig.width=10, fig.height=8}
# XGBoost model (workflow) từ script 06 sử dụng engine "xgboost"

# Cách 1: Dùng vip (khuyến nghị)
# vip_xgb <- vip(model_xgb_tuned, num_features = 20, geom = "col", aesthetics = list(fill = "salmon")) +
#   labs(title = "Độ quan trọng của Biến - XGBoost (Tuned)",
#        subtitle = "Dựa trên phép đo mặc định (thường là Gain cho XGBoost)") +
#   theme_minimal()
# print(vip_xgb)

# Cách 2: Trích xuất mô hình xgboost gốc
if (inherits(model_xgb_tuned$fit$fit$fit, "xgb.Booster")) {
    xgb_engine_model <- model_xgb_tuned$fit$fit$fit
    
    xgb_importance_matrix <- xgb.importance(model = xgb_engine_model)
    xgb_importance_top20 <- head(xgb_importance_matrix, 20)

    vip_xgb_plot <- xgb.ggplot.importance(xgb_importance_top20) +
      labs(title = "Top 20 Biến Quan trọng - XGBoost (Tuned)",
           subtitle = "Dựa trên Gain (mặc định từ xgb.importance)") +
      theme_minimal()
    print(vip_xgb_plot)
    
    ggsave(paste0(RESULTS_DIR, "feature_importance/xgb_feature_importance_final.png"), plot = vip_xgb_plot, width = 10, height = 8)
    cat("Đã lưu biểu đồ độ quan trọng XGBoost vào thư mục results/feature_importance.\n")
} else {
    cat("Không thể trích xuất mô hình xgboost gốc từ workflow. Sử dụng vip() nếu có thể.\n")
     tryCatch({
        vip_xgb_plot <- vip(model_xgb_tuned, num_features = 20, geom = "col", aesthetics = list(fill = "salmon")) +
          labs(title = "Độ quan trọng của Biến - XGBoost (Tuned)",
               subtitle = "Mặc định từ vip()") +
          theme_minimal()
        print(vip_xgb_plot)
        ggsave(paste0(RESULTS_DIR, "feature_importance/xgb_feature_importance_final.png"), plot = vip_xgb_plot, width = 10, height = 8)
        cat("Đã lưu biểu đồ độ quan trọng XGBoost (từ vip) vào thư mục results/feature_importance.\n")
    }, error = function(e) {
        cat("Lỗi khi tạo biểu đồ vip cho XGBoost:", conditionMessage(e), "\n")
    })
}
```

## 6. Kết luận và Thảo luận

Dựa trên các số liệu và biểu đồ:

1.  **Hiệu suất tổng thể**: (Nhận xét mô hình nào có AUC-ROC, AUC-PR, F1-Score cao nhất. Ví dụ: "Mô hình XGBoost (Tuned) cho thấy hiệu suất tổng thể tốt nhất với AUC-ROC là [giá trị] và AUC-PR là [giá trị], theo sát là Random Forest (Tuned). Logistic Regression, mặc dù đơn giản hơn, vẫn cho kết quả khả quan nhưng kém hơn các mô hình ensemble.")
2.  **Khả năng xác định khách hàng vỡ nợ (Recall Class 1)**: (Nhận xét về Recall cho lớp "1". Ví dụ: "Mô hình [Tên mô hình] có Recall cao nhất cho lớp vỡ nợ, nghĩa là nó xác định được [giá trị]% khách hàng thực sự sẽ vỡ nợ. Đây là một yếu tố quan trọng nếu mục tiêu là giảm thiểu tối đa rủi ro bỏ sót.")
3.  **Độ chính xác khi dự đoán vỡ nợ (Precision Class 1)**: (Nhận xét về Precision cho lớp "1". Ví dụ: "Mô hình [Tên mô hình] có Precision cao nhất, nghĩa là trong số các khách hàng được dự đoán là vỡ nợ, [giá trị]% thực sự vỡ nợ. Điều này quan trọng nếu chi phí của False Positive cao.")
4.  **Các yếu tố ảnh hưởng chính**: (Nhận xét từ biểu đồ Feature Importance. Ví dụ: "Các biến như PAY_0, LIMIT_BAL, PAY_AMT1 liên tục xuất hiện là những yếu tố quan trọng nhất trong cả Random Forest và XGBoost, cho thấy lịch sử thanh toán gần đây và hạn mức tín dụng đóng vai trò then chốt trong việc dự đoán khả năng vỡ nợ.")
5.  **Hạn chế và Hướng phát triển**:
    *   Dữ liệu vẫn có thể mất cân bằng dù đã SMOTE, ảnh hưởng đến Recall.
    *   Có thể thử nghiệm thêm các kỹ thuật feature engineering phức tạp hơn.
    *   Xem xét điều chỉnh ngưỡng quyết định (threshold tuning) để tối ưu hóa theo một mục tiêu kinh doanh cụ thể (ví dụ, tối đa hóa Recall với một mức Precision chấp nhận được).

Báo cáo này cung cấp một cái nhìn toàn diện về hiệu suất của các mô hình. Lựa chọn mô hình cuối cùng để triển khai sẽ phụ thuộc vào các yêu cầu cụ thể của bài toán, bao gồm sự cân bằng giữa các độ đo và khả năng diễn giải của mô hình.

---

